{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE GRA v2.5 Pipeline - Optimal β Parameter\n",
    "\n",
    "Complete pipeline for VAE GRA v2.5 with β=0.05 (optimal clustering performance).\n",
    "\n",
    "**Key Innovation**: β=0.05 preserves feature correlations while preventing posterior collapse.\n",
    "\n",
    "**Performance**: ARI=0.253 at k=20 (+52% vs v2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "# Try UMAP, fall back to PCA if unavailable\n",
    "try:\n",
    "    from umap import UMAP\n",
    "    UMAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"UMAP not available, will use PCA for dimensionality reduction\")\n",
    "\n",
    "sys.path.insert(0, '/home/utig5/johna/bhai/ml_models')\n",
    "\n",
    "from vae_lithology_gra_v2_5_model import VAE, DistributionAwareScaler\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Create Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('/home/utig5/johna/bhai/vae_training_data_v2_20cm.csv')\n",
    "\n",
    "print(f\"Total dataset: {len(df):,} samples from {df['Borehole_ID'].nunique()} boreholes\")\n",
    "print(f\"Features: GRA, MS, NGR, RGB (6D input)\")\n",
    "print(f\"Lithologies: {df['Principal'].nunique()} unique types\")\n",
    "\n",
    "# Create same splits as training\n",
    "unique_boreholes = df['Borehole_ID'].unique()\n",
    "train_boreholes, test_boreholes = train_test_split(\n",
    "    unique_boreholes, train_size=0.85, random_state=42\n",
    ")\n",
    "train_boreholes, val_boreholes = train_test_split(\n",
    "    train_boreholes, train_size=0.7/0.85, random_state=42\n",
    ")\n",
    "\n",
    "test_mask = df['Borehole_ID'].isin(test_boreholes)\n",
    "df_test = df[test_mask].copy()\n",
    "\n",
    "print(f\"\\nTest set: {len(test_boreholes)} boreholes, {len(df_test):,} samples\")\n",
    "print(f\"Test lithologies: {df_test['Principal'].nunique()} unique types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trained Models (v2.1 and v2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load v2.5 with β=0.05 (optimal)\n",
    "print(\"Loading VAE GRA v2.5 (β=0.05)...\")\n",
    "model_v2_5 = VAE(input_dim=6, latent_dim=8, hidden_dims=[32, 16])\n",
    "\n",
    "checkpoint_v2_5 = torch.load(\n",
    "    '/home/utig5/johna/bhai/ml_models/checkpoints/vae_gra_v2_5_beta0.05_latent8.pth',\n",
    "    map_location='cpu', weights_only=True\n",
    ")\n",
    "\n",
    "model_v2_5.load_state_dict(checkpoint_v2_5['model_state_dict'])\n",
    "model_v2_5.eval()\n",
    "print(f\"v2.5 model loaded (β={checkpoint_v2_5.get('beta', 0.05)})\")\n",
    "\n",
    "# Load v2.1 for comparison\n",
    "print(\"\\nLoading VAE GRA v2.1 (β=1.0) for comparison...\")\n",
    "model_v2_1 = VAE(input_dim=6, latent_dim=8, hidden_dims=[32, 16])\n",
    "\n",
    "try:\n",
    "    checkpoint_v2_1 = torch.load(\n",
    "        '/home/utig5/johna/bhai/ml_models/checkpoints/vae_gra_v2_1_latent8.pth',\n",
    "        map_location='cpu', weights_only=True\n",
    "    )\n",
    "    model_v2_1.load_state_dict(checkpoint_v2_1)\n",
    "except:\n",
    "    # Try with weights_only=False if needed\n",
    "    import __main__\n",
    "    from vae_lithology_gra_v2_1_model import DistributionAwareScaler as DAS\n",
    "    __main__.DistributionAwareScaler = DAS\n",
    "    \n",
    "    checkpoint_v2_1 = torch.load(\n",
    "        '/home/utig5/johna/bhai/ml_models/checkpoints/vae_gra_v2_1_latent8.pth',\n",
    "        map_location='cpu', weights_only=False\n",
    "    )\n",
    "    model_v2_1.load_state_dict(checkpoint_v2_1['model_state_dict'])\n",
    "\n",
    "model_v2_1.eval()\n",
    "print(\"v2.1 model loaded (β=1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Latent Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Bulk density (GRA)', 'Magnetic susceptibility (instr. units)',\n",
    "                'NGR total counts (cps)', 'R', 'G', 'B']\n",
    "\n",
    "X_test = df_test[feature_cols].values\n",
    "lithology = df_test['Principal'].values\n",
    "\n",
    "# Scale features with distribution-aware scaler\n",
    "print(\"Scaling features with distribution-aware scaler...\")\n",
    "scaler = DistributionAwareScaler()\n",
    "X_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Extract latent representations from both models\n",
    "print(\"\\nExtracting latent representations...\")\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.FloatTensor(X_scaled)\n",
    "    \n",
    "    # v2.5 (β=0.05)\n",
    "    mu_v2_5, logvar_v2_5 = model_v2_5.encode(X_tensor)\n",
    "    latent_v2_5 = mu_v2_5.numpy()\n",
    "    \n",
    "    # v2.1 (β=1.0)\n",
    "    mu_v2_1, logvar_v2_1 = model_v2_1.encode(X_tensor)\n",
    "    latent_v2_1 = mu_v2_1.numpy()\n",
    "    \n",
    "    # Reconstruction (v2.5)\n",
    "    X_recon_v2_5 = model_v2_5.decode(mu_v2_5).numpy()\n",
    "\n",
    "print(f\"Latent shape: {latent_v2_5.shape} (8D)\")\n",
    "print(f\"Reconstruction shape: {X_recon_v2_5.shape} (6D)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. UMAP/PCA Projection for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UMAP_AVAILABLE:\n",
    "    print(\"Computing UMAP projection (8D → 2D)...\")\n",
    "    reducer_v2_5 = UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
    "    latent_2d_v2_5 = reducer_v2_5.fit_transform(latent_v2_5)\n",
    "    \n",
    "    reducer_v2_1 = UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
    "    latent_2d_v2_1 = reducer_v2_1.fit_transform(latent_v2_1)\n",
    "    \n",
    "    method = \"UMAP\"\n",
    "else:\n",
    "    print(\"Computing PCA projection (8D → 2D)...\")\n",
    "    reducer_v2_5 = PCA(n_components=2, random_state=42)\n",
    "    latent_2d_v2_5 = reducer_v2_5.fit_transform(latent_v2_5)\n",
    "    \n",
    "    reducer_v2_1 = PCA(n_components=2, random_state=42)\n",
    "    latent_2d_v2_1 = reducer_v2_1.fit_transform(latent_v2_1)\n",
    "    \n",
    "    method = \"PCA\"\n",
    "    print(f\"Explained variance: {reducer_v2_5.explained_variance_ratio_.sum():.1%}\")\n",
    "\n",
    "print(f\"2D projection shape: {latent_2d_v2_5.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cluster Analysis (K-Means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple k values\n",
    "k_values = [10, 12, 15, 20]\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    # v2.5 clustering\n",
    "    kmeans_v2_5 = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_v2_5 = kmeans_v2_5.fit_predict(latent_v2_5)\n",
    "    \n",
    "    ari_v2_5 = adjusted_rand_score(lithology, labels_v2_5)\n",
    "    sil_v2_5 = silhouette_score(latent_v2_5, labels_v2_5)\n",
    "    \n",
    "    # v2.1 clustering\n",
    "    kmeans_v2_1 = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_v2_1 = kmeans_v2_1.fit_predict(latent_v2_1)\n",
    "    \n",
    "    ari_v2_1 = adjusted_rand_score(lithology, labels_v2_1)\n",
    "    sil_v2_1 = silhouette_score(latent_v2_1, labels_v2_1)\n",
    "    \n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'v2.5_ARI': ari_v2_5,\n",
    "        'v2.5_Silhouette': sil_v2_5,\n",
    "        'v2.1_ARI': ari_v2_1,\n",
    "        'v2.1_Silhouette': sil_v2_1,\n",
    "        'labels_v2_5': labels_v2_5,\n",
    "        'labels_v2_1': labels_v2_1\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nClustering Performance Comparison:\")\n",
    "print(df_results[['k', 'v2.5_ARI', 'v2.1_ARI', 'v2.5_Silhouette', 'v2.1_Silhouette']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization: Latent Space Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot side-by-side comparison of v2.1 vs v2.5\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# v2.1 (β=1.0)\n",
    "scatter1 = axes[0].scatter(latent_2d_v2_1[:, 0], latent_2d_v2_1[:, 1], \n",
    "                           c=results[2]['labels_v2_1'], cmap='tab20', \n",
    "                           s=1, alpha=0.5)\n",
    "axes[0].set_title(f'VAE GRA v2.1 (β=1.0)\\n{method} Projection, k=15\\nARI={results[2][\"v2.1_ARI\"]:.3f}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel(f'{method}1', fontsize=12)\n",
    "axes[0].set_ylabel(f'{method}2', fontsize=12)\n",
    "\n",
    "# v2.5 (β=0.05)\n",
    "scatter2 = axes[1].scatter(latent_2d_v2_5[:, 0], latent_2d_v2_5[:, 1], \n",
    "                           c=results[2]['labels_v2_5'], cmap='tab20', \n",
    "                           s=1, alpha=0.5)\n",
    "axes[1].set_title(f'VAE GRA v2.5 (β=0.05)\\n{method} Projection, k=15\\nARI={results[2][\"v2.5_ARI\"]:.3f}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel(f'{method}1', fontsize=12)\n",
    "axes[1].set_ylabel(f'{method}2', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vae_v2_5_outputs/latent_comparison_v2_1_vs_v2_5.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Improvement: {(results[2]['v2.5_ARI'] - results[2]['v2.1_ARI']) / results[2]['v2.1_ARI'] * 100:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Colored by Lithology (Top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 lithologies\n",
    "top_lithologies = df_test['Principal'].value_counts().head(10).index.tolist()\n",
    "lithology_colors = {lith: i for i, lith in enumerate(top_lithologies)}\n",
    "lithology_colors['Other'] = len(top_lithologies)\n",
    "\n",
    "# Map lithologies to colors\n",
    "lithology_mapped = [lithology_colors.get(lith, lithology_colors['Other']) for lith in lithology]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# v2.1\n",
    "scatter1 = axes[0].scatter(latent_2d_v2_1[:, 0], latent_2d_v2_1[:, 1], \n",
    "                           c=lithology_mapped, cmap='tab20', \n",
    "                           s=1, alpha=0.5)\n",
    "axes[0].set_title(f'VAE GRA v2.1 (β=1.0)\\nColored by Lithology (Top 10)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel(f'{method}1', fontsize=12)\n",
    "axes[0].set_ylabel(f'{method}2', fontsize=12)\n",
    "\n",
    "# v2.5\n",
    "scatter2 = axes[1].scatter(latent_2d_v2_5[:, 0], latent_2d_v2_5[:, 1], \n",
    "                           c=lithology_mapped, cmap='tab20', \n",
    "                           s=1, alpha=0.5)\n",
    "axes[1].set_title(f'VAE GRA v2.5 (β=0.05)\\nColored by Lithology (Top 10)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel(f'{method}1', fontsize=12)\n",
    "axes[1].set_ylabel(f'{method}2', fontsize=12)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=plt.cm.tab20(lithology_colors[lith]), label=lith) \n",
    "                   for lith in top_lithologies]\n",
    "legend_elements.append(Patch(facecolor=plt.cm.tab20(lithology_colors['Other']), label='Other'))\n",
    "\n",
    "fig.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1.0, 0.5), \n",
    "           fontsize=10, frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vae_v2_5_outputs/latent_by_lithology_v2_1_vs_v2_5.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 lithologies:\")\n",
    "for i, lith in enumerate(top_lithologies, 1):\n",
    "    count = (df_test['Principal'] == lith).sum()\n",
    "    print(f\"{i:2d}. {lith:30s} ({count:6,} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. High-Purity Cluster Analysis (k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k=20 (best performance)\n",
    "k = 20\n",
    "labels_v2_5 = results[3]['labels_v2_5']  # k=20 is index 3\n",
    "\n",
    "# Analyze cluster purity\n",
    "cluster_info = []\n",
    "\n",
    "for cluster_id in range(k):\n",
    "    cluster_mask = labels_v2_5 == cluster_id\n",
    "    cluster_lithologies = lithology[cluster_mask]\n",
    "    \n",
    "    if len(cluster_lithologies) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Most common lithology\n",
    "    from collections import Counter\n",
    "    counts = Counter(cluster_lithologies)\n",
    "    dominant_lith, dominant_count = counts.most_common(1)[0]\n",
    "    \n",
    "    purity = dominant_count / len(cluster_lithologies) * 100\n",
    "    \n",
    "    cluster_info.append({\n",
    "        'Cluster': cluster_id,\n",
    "        'Size': len(cluster_lithologies),\n",
    "        'Dominant': dominant_lith,\n",
    "        'Purity': purity,\n",
    "        'Count': dominant_count\n",
    "    })\n",
    "\n",
    "df_clusters = pd.DataFrame(cluster_info)\n",
    "df_clusters = df_clusters.sort_values('Purity', ascending=False)\n",
    "\n",
    "print(f\"\\nHigh-Purity Clusters (k={k}, v2.5 β=0.05):\")\n",
    "print(\"=\"*80)\n",
    "print(df_clusters.head(15).to_string(index=False))\n",
    "\n",
    "# Count clusters with >50% purity\n",
    "high_purity = (df_clusters['Purity'] > 50).sum()\n",
    "print(f\"\\nClusters with >50% purity: {high_purity}/{k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Reconstruction Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstruction quality for all 6 features\n",
    "feature_names = ['GRA', 'MS', 'NGR', 'R', 'G', 'B']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (feature_name, ax) in enumerate(zip(feature_names, axes)):\n",
    "    # Sample 5000 points for clearer visualization\n",
    "    sample_idx = np.random.choice(len(X_scaled), 5000, replace=False)\n",
    "    \n",
    "    x_orig = X_scaled[sample_idx, i]\n",
    "    x_recon = X_recon_v2_5[sample_idx, i]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(x_orig, x_recon, s=1, alpha=0.3)\n",
    "    \n",
    "    # Perfect reconstruction line\n",
    "    lims = [min(x_orig.min(), x_recon.min()), max(x_orig.max(), x_recon.max())]\n",
    "    ax.plot(lims, lims, 'r--', alpha=0.5, linewidth=2, label='Perfect')\n",
    "    \n",
    "    # Calculate R²\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2 = r2_score(x_orig, x_recon)\n",
    "    \n",
    "    ax.set_title(f'{feature_name}\\nR² = {r2:.3f}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Original (scaled)', fontsize=10)\n",
    "    ax.set_ylabel('Reconstructed (scaled)', fontsize=10)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('VAE GRA v2.5 (β=0.05) - Reconstruction Quality', \n",
    "             fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('vae_v2_5_outputs/reconstruction_quality_v2_5.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Performance vs k (Line Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ARI comparison\n",
    "axes[0].plot(df_results['k'], df_results['v2.1_ARI'], \n",
    "             marker='o', linewidth=2, markersize=8, label='v2.1 (β=1.0)')\n",
    "axes[0].plot(df_results['k'], df_results['v2.5_ARI'], \n",
    "             marker='s', linewidth=2, markersize=8, label='v2.5 (β=0.05)')\n",
    "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0].set_ylabel('Adjusted Rand Index', fontsize=12)\n",
    "axes[0].set_title('ARI vs k', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(df_results['k'])\n",
    "\n",
    "# Silhouette comparison\n",
    "axes[1].plot(df_results['k'], df_results['v2.1_Silhouette'], \n",
    "             marker='o', linewidth=2, markersize=8, label='v2.1 (β=1.0)')\n",
    "axes[1].plot(df_results['k'], df_results['v2.5_Silhouette'], \n",
    "             marker='s', linewidth=2, markersize=8, label='v2.5 (β=0.05)')\n",
    "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1].set_title('Silhouette vs k', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(df_results['k'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vae_v2_5_outputs/performance_vs_k.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print improvement table\n",
    "print(\"\\nImprovement (v2.5 vs v2.1):\")\n",
    "print(\"=\"*60)\n",
    "for _, row in df_results.iterrows():\n",
    "    k = int(row['k'])\n",
    "    ari_improvement = (row['v2.5_ARI'] - row['v2.1_ARI']) / row['v2.1_ARI'] * 100\n",
    "    print(f\"k={k:2d}: ARI improvement = {ari_improvement:+6.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Feature Importance via Latent Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation between input features and latent dimensions\n",
    "correlations = np.zeros((6, 8))\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(8):\n",
    "        correlations[i, j] = np.corrcoef(X_scaled[:, i], latent_v2_5[:, j])[0, 1]\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlations, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            xticklabels=[f'z{i}' for i in range(8)],\n",
    "            yticklabels=feature_names,\n",
    "            cbar_kws={'label': 'Pearson Correlation'})\n",
    "plt.title('Feature → Latent Correlations (v2.5, β=0.05)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Latent Dimension', fontsize=12)\n",
    "plt.ylabel('Input Feature (scaled)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('vae_v2_5_outputs/feature_latent_correlations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: β=0.05 allows latent dimensions to capture correlated patterns,\")\n",
    "print(\"unlike β=1.0 which forces independence (disentanglement).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"VAE GRA v2.5 (β=0.05) - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "print(f\"Dataset: {len(df_test):,} samples, {df_test['Principal'].nunique()} lithologies\")\n",
    "print(f\"Model: 6D input (GRA, MS, NGR, RGB) → 8D latent → 6D output\")\n",
    "print(f\"β parameter: 0.05 (optimal for clustering)\")\n",
    "print()\n",
    "\n",
    "print(\"Best Performance:\")\n",
    "best_idx = df_results['v2.5_ARI'].idxmax()\n",
    "best_k = int(df_results.loc[best_idx, 'k'])\n",
    "best_ari = df_results.loc[best_idx, 'v2.5_ARI']\n",
    "best_sil = df_results.loc[best_idx, 'v2.5_Silhouette']\n",
    "baseline_ari = df_results.loc[best_idx, 'v2.1_ARI']\n",
    "\n",
    "print(f\"  k = {best_k}\")\n",
    "print(f\"  ARI = {best_ari:.3f}\")\n",
    "print(f\"  Silhouette = {best_sil:.3f}\")\n",
    "print(f\"  Improvement vs v2.1: {(best_ari - baseline_ari) / baseline_ari * 100:+.1f}%\")\n",
    "print()\n",
    "\n",
    "print(\"Comparison to v2.1 (β=1.0):\")\n",
    "avg_improvement = ((df_results['v2.5_ARI'].mean() - df_results['v2.1_ARI'].mean()) / \n",
    "                   df_results['v2.1_ARI'].mean() * 100)\n",
    "print(f\"  Average ARI improvement: {avg_improvement:+.1f}%\")\n",
    "print()\n",
    "\n",
    "print(\"Key Innovation:\")\n",
    "print(\"  β=0.05 preserves feature correlations (MS↔alteration, GRA↔compaction)\")\n",
    "print(\"  that are geologically meaningful for lithology discrimination.\")\n",
    "print()\n",
    "print(\"  High β (disentanglement) destroys these correlations, hurting clustering.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "import os\n",
    "os.makedirs('vae_v2_5_outputs', exist_ok=True)\n",
    "\n",
    "# Save numerical results\n",
    "df_results[['k', 'v2.5_ARI', 'v2.5_Silhouette', 'v2.1_ARI', 'v2.1_Silhouette']].to_csv(\n",
    "    'vae_v2_5_outputs/clustering_performance.csv', index=False\n",
    ")\n",
    "\n",
    "# Save cluster analysis\n",
    "df_clusters.to_csv('vae_v2_5_outputs/cluster_purity_k20.csv', index=False)\n",
    "\n",
    "print(\"Results saved to vae_v2_5_outputs/\")\n",
    "print(\"  - clustering_performance.csv\")\n",
    "print(\"  - cluster_purity_k20.csv\")\n",
    "print(\"  - latent_comparison_v2_1_vs_v2_5.png\")\n",
    "print(\"  - latent_by_lithology_v2_1_vs_v2_5.png\")\n",
    "print(\"  - reconstruction_quality_v2_5.png\")\n",
    "print(\"  - performance_vs_k.png\")\n",
    "print(\"  - feature_latent_correlations.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
